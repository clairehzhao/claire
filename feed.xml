<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://clairehzhao.github.io/claire/feed.xml" rel="self" type="application/atom+xml" /><link href="https://clairehzhao.github.io/claire/" rel="alternate" type="text/html" /><updated>2023-04-03T02:36:10-05:00</updated><id>https://clairehzhao.github.io/claire/feed.xml</id><title type="html">claireâ€™s apcsp blog</title><subtitle>My Blog Site!</subtitle><entry><title type="html">MCQ Test 4</title><link href="https://clairehzhao.github.io/claire/week28/markdown/2023/04/02/mc-4.html" rel="alternate" type="text/html" title="MCQ Test 4" /><published>2023-04-02T00:00:00-05:00</published><updated>2023-04-02T00:00:00-05:00</updated><id>https://clairehzhao.github.io/claire/week28/markdown/2023/04/02/mc#4</id><author><name></name></author><category term="week28" /><category term="markdown" /><summary type="html"><![CDATA[College Board MC Quiz 4]]></summary></entry><entry><title type="html">Data Structures- Hashmaps, Sets, Hash Tables, Hashing and Collisions</title><link href="https://clairehzhao.github.io/claire/2023/03/29/DS-hashmaps.html" rel="alternate" type="text/html" title="Data Structures- Hashmaps, Sets, Hash Tables, Hashing and Collisions" /><published>2023-03-29T00:00:00-05:00</published><updated>2023-03-29T00:00:00-05:00</updated><id>https://clairehzhao.github.io/claire/2023/03/29/DS-hashmaps</id><author><name></name></author><summary type="html"><![CDATA[Observing hashmaps with python dictionaries]]></summary></entry><entry><title type="html">Ap Unit4 3a Parallel Computing</title><link href="https://clairehzhao.github.io/claire/2023/03/29/AP-unit4-3a-parallel-computing.ipynb" rel="alternate" type="text/html" title="Ap Unit4 3a Parallel Computing" /><published>2023-03-29T00:00:00-05:00</published><updated>2023-03-29T00:00:00-05:00</updated><id>https://clairehzhao.github.io/claire/2023/03/29/AP-unit4-3a-parallel-computing</id><author><name></name></author><summary type="html"><![CDATA[{ "cells": [ { "attachments": {}, "cell_type": "markdown", "metadata": {}, "source": [ "# Unit 4.3a Parallel Computing\n", "> Observe an algorithm using parallel computing in Python Code. Monitor processes on host.\n", "- toc: true\n", "- type: ap\n", "- week: 28" ] }, { "attachments": {}, "cell_type": "markdown", "metadata": {}, "source": [ "## Analyzing Parallel Computing\n", "> Once again we will use image lab, this time to review Parallel Computing.\n", "- Change baseWidth in this line in code to increase computation requirements: ```def process_image(image, baseWidth=512):``` For instance 320, 512, 1024, 2048, 4096.\n", "- Compare Sequential and Parallel computing code and time to achieve outputs" ] }, { "cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": [ "from IPython.display import HTML, display\n", "from pathlib import Path # https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f\n", "from PIL import Image as pilImage # as PIL Image is used to avoid conflicts\n", "from io import BytesIO\n", "import base64\n", "import numpy as np\n", "\n", "\n", "# prepares a series of images\n", "def image_data(path=Path(\"images/\"), images=None): # path of static images is defaulted\n", " if images is None: # default image\n", " images = [\n", " {'source': \"Internet\", 'label': \"Green Square\", 'file': \"green-square-16.png\"},\n", " {'source': \"Peter Carolin\", 'label': \"Clouds Impression\", 'file': \"clouds-impression.png\"},\n", " {'source': \"Peter Carolin\", 'label': \"Lassen Volcano\", 'file': \"lassen-volcano.jpg\"}\n", " ]\n", " for image in images:\n", " # File to open\n", " image['filename'] = path / image['file'] # file with path\n", " return images\n", "\n", "# Scale to baseWidth\n", "def scale_image(img, baseWidth):\n", " scalePercent = (baseWidth/float(img.size[0]))\n", " scaleHeight = int((float(img.size[1])*float(scalePercent)))\n", " scale = (baseWidth, scaleHeight)\n", " return img.resize(scale)\n", "\n", "# PIL image converted to base64\n", "def image_to_base64(img, format):\n", " with BytesIO() as buffer:\n", " img.save(buffer, format)\n", " return base64.b64encode(buffer.getvalue()).decode()\n", " \n", "# Convert pixels to Grey Scale\n", "def grey_pixel(pixel):\n", " average = (pixel[0] + pixel[1] + pixel[2]) // 3 # average pixel values and use // for integer division\n", " if len(pixel) > 3:\n", " return( (average, average, average, pixel[3]) ) # PNG format\n", " else:\n", " return( (average, average, average) )\n", " \n", "# Convert pixels to Red Scale\n", "def red_pixel(pixel):\n", " if len(pixel) > 3:\n", " return( (pixel[0], 0, 0, pixel[3]) ) # PNG format\n", " else:\n", " return( (pixel[0], 0, 0) )\n", " \n", "# Convert pixels to Red Scale\n", "def green_pixel(pixel):\n", " if len(pixel) > 3:\n", " return( (0, pixel[1], 0, pixel[3]) ) # PNG format\n", " else:\n", " return( (0, pixel[1], 0) )\n", " \n", "# Convert pixels to Red Scale\n", "def blue_pixel(pixel):\n", " if len(pixel) > 3:\n", " return( (0, 0, pixel[2], pixel[3]) ) # PNG format\n", " else:\n", " return( (0, 0, pixel[2]) )\n", " \n", "# Set Properties of Image, Scale, and convert to Base64\n", "def image_management(image, baseWidth): # path of static images is defaulted \n", " # Image open return PIL image object\n", " img = pilImage.open(image['filename'])\n", " \n", " # Python Image Library operations\n", " image['format'] = img.format\n", " image['mode'] = img.mode\n", " image['size'] = img.size\n", " # Scale the Image\n", " img = scale_image(img, baseWidth)\n", " image['pil'] = img\n", " image['scaled_size'] = img.size\n", " image['numpy'] = np.array(img.getdata())\n", " # Scaled HTML\n", " image['html'] = '' % image_to_base64(image['pil'], image['format'])\n", " \n", " # Grey HTML\n", " # each pixel in numpy array is turned to grey \n", " # then resulting list, using List Comprehension, is put back into img \n", " img.putdata([grey_pixel(pixel) for pixel in image['numpy']])\n", " image['html_grey'] = '' % image_to_base64(img, image['format'])\n", " \n", " # Red HTML\n", " img.putdata([red_pixel(pixel) for pixel in image['numpy']])\n", " image['html_red'] = '' % image_to_base64(img, image['format'])\n", " \n", " # Green HTML\n", " img.putdata([green_pixel(pixel) for pixel in image['numpy']])\n", " image['html_green'] = '' % image_to_base64(img, image['format'])\n", " \n", " # Blue HTML\n", " img.putdata([blue_pixel(pixel) for pixel in image['numpy']])\n", " image['html_blue'] = '' % image_to_base64(img, image['format'])\n", " \n", " \n", "def process_image(image, baseWidth=2048):\n", " image_management(image, baseWidth)\n", " print(\"---- meta data -----\")\n", " print(image['label'])\n", " print(image['source'])\n", " print(image['format'])\n", " print(image['mode'])\n", " print(\"Original size: \", image['size'])\n", " print(\"Scaled size: \", image['scaled_size'])\n", " \n", " print(\"-- images --\")\n", " display(HTML(image['html'])) \n", " display(HTML(image['html_grey'])) \n", " display(HTML(image['html_red'])) \n", " display(HTML(image['html_green'])) \n", " display(HTML(image['html_blue'])) \n" ] }, { "attachments": {}, "cell_type": "markdown", "metadata": {}, "source": [ "## Sequential Processing \n", "> The for loop iterates over the list of images and processes them one at a time, in order." ] }, { "cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "---- meta data -----\n", "Green Square\n", "Internet\n", "PNG\n", "RGBA\n", "Original size: (16, 16)\n", "Scaled size: (2048, 2048)\n", "-- images --\n" ] }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "name": "stdout", "output_type": "stream", "text": [ "---- meta data -----\n", "Clouds Impression\n", "Peter Carolin\n", "PNG\n", "RGBA\n", "Original size: (320, 234)\n", "Scaled size: (2048, 1497)\n", "-- images --\n" ] }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "name": "stdout", "output_type": "stream", "text": [ "---- meta data -----\n", "Lassen Volcano\n", "Peter Carolin\n", "JPEG\n", "RGB\n", "Original size: (2792, 2094)\n", "Scaled size: (2048, 1536)\n", "-- images --\n" ] }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "name": "stdout", "output_type": "stream", "text": [ "\n" ] } ], "source": [ "# Jupyter Notebook Visualization of Images\n", "if __name__ == \"__main__\":\n", " # setup default images\n", " images = image_data()\n", "\n", " # Sequential Processing \n", " for image in images:\n", " process_image(image)\n", " \n", " print()" ] }, { "attachments": {}, "cell_type": "markdown", "metadata": {}, "source": [ "## Parallel Computing\n", "\n", " > In parallel or concurrent mode, the ThreadPoolExecutor is used to submit each image to a separate worker thread, allowing multiple images to be processed simultaneously. Multithreading allows multiple concurrent tasks of a process at the same time. The executor.map() method is used to apply the process_image function to each image in the images list. \n", " - The order in which the images are processed is not guaranteed, as threads are performed simultaneously." ] }, { "cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "---- meta data -----\n", "Lassen Volcano\n", "Peter Carolin\n", "JPEG\n", "RGB\n", "Original size: (2792, 2094)\n", "Scaled size: (2048, 1536)\n", "-- images --\n" ] }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "name": "stdout", "output_type": "stream", "text": [ "---- meta data -----\n", "Clouds Impression\n", "Peter Carolin\n", "PNG\n", "RGBA\n", "Original size: (320, 234)\n", "Scaled size: (2048, 1497)\n", "-- images --\n" ] }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "name": "stdout", "output_type": "stream", "text": [ "---- meta data -----\n", "Green Square\n", "Internet\n", "PNG\n", "RGBA\n", "Original size: (16, 16)\n", "Scaled size: (2048, 2048)\n", "-- images --\n" ] }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "data": { "text/html": [ "" ], "text/plain": [ "" ] }, "metadata": {}, "output_type": "display_data" }, { "name": "stdout", "output_type": "stream", "text": [ "\n" ] } ], "source": [ "import concurrent.futures\n", "\n", "# Jupyter Notebook Visualization of Images\n", "if __name__ == \"__main__\":\n", " # setup default images\n", " images = image_data()\n", " \n", " # Parallel Processsing\n", " # executor allocates threads, it considers core execution capability of machine\n", " with concurrent.futures.ThreadPoolExecutor() as executor:\n", " executor.map(process_image, images) # order is not predictable\n", " \n", " print()" ] }, { "attachments": {}, "cell_type": "markdown", "metadata": {}, "source": [ "## Observing Parallel Computing and Threads\n", "> You can observe Processes, CPU Percentage, and Threads with Tools on your machine. Common tools to monitor performance are Activity Monitor on MacOS or Task Manager on Windows. \n", "\n", "- This example is using ```top``` launched in VSCode Terminal. (mac)\n", "- Try ```top -H``` for linux.\n", "![](images/top.png)\n", " - PID is Process ID. \n", " - COMMAND is task running on machine. Python is activated when running this Jupyter notebook.\n", " - #TH is number of threads. This increases from 15/1 to 18/1 on my machine when running python parallel computing example.\n" ] }, { "attachments": {}, "cell_type": "markdown", "metadata": {}, "source": [ "## Hacks\n", "> AP Classroom. Provide answers and thoughts on theoritical question form college board Video in section 4.3. They start at about the 9 minute mark.\n", "- Example 1\n", "\n", "The answer to the first example is 50 seconds. This is because one proccessor can run proccess Y and Z and that will take 40 seconds. X is left to run on its own and will take 50 seconds. This means by the time all of them are done it will have taken 50 seconds.\n", "\n", "- Example 2\n", "\n", "The answer to this would be 25 seconds. This is because when the two proccesses are running parallel it will be 70 seconds. When the proccesses run both in parallel with yield a minimum time of 45 seconds. 70 - 45 = 25 seconds\n", "\n", "> Data Structures. Build a List Comprehension example\n", "- list = [calc(item) for item in items]" ] }, { "cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": [ "folklore = [\n", " \"the 1\",\n", " \"cardigan\",\n", " \"the last great american dynasty\",\n", " \"exile (feat. Bon Iver)\",\n", " \"my tears ricochet\",\n", " \"mirrorball\",\n", " \"seven\",\n", " \"august\",\n", " \"this is me trying\",\n", " \"illicit affairs\",\n", " \"invisible string\",\n", " \"mad woman\",\n", " \"epiphany\",\n", " \"betty\",\n", " \"peace\",\n", " \"hoax\",\n", " \"the lakes - bonus track\",\n", "]" ] }, { "cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "['the last great american dynasty', 'exile (feat. Bon Iver)', 'my tears ricochet', 'this is me trying', 'illicit affairs', 'invisible string', 'the lakes - bonus track']\n" ] } ], "source": [ "newlist = [x for x in folklore if len(x) > 10]\n", "print(newlist)" ] }, { "cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "['THE 1', 'cardigan', 'THE LAST GREAT AMERICAN DYNASTY', 'exile (feat. bon iver)', 'MY TEARS RICOCHET', 'mirrorball', 'SEVEN', 'august', 'THIS IS ME TRYING', 'illicit affairs', 'INVISIBLE STRING', 'mad woman', 'EPIPHANY', 'betty', 'PEACE', 'hoax', 'THE LAKES - BONUS TRACK']\n" ] } ], "source": [ "for i, item in enumerate(folklore): # alternate the capital and lowercase\n", " if i % 2 == 0:\n", " folklore[i] = item.upper()\n", " else:\n", " folklore[i] = item.lower()\n", "print(folklore)" ] }, { "cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [ { "name": "stdout", "output_type": "stream", "text": [ "['THE LAKES - BONUS TRACK', 'hoax', 'PEACE', 'betty', 'EPIPHANY', 'mad woman', 'INVISIBLE STRING', 'illicit affairs', 'THIS IS ME TRYING', 'august', 'SEVEN', 'mirrorball', 'MY TEARS RICOCHET', 'exile (feat. bon iver)', 'THE LAST GREAT AMERICAN DYNASTY', 'cardigan', 'THE 1']\n" ] } ], "source": [ "folklore.reverse() # reverse the list\n", "print(folklore)" ] } ], "metadata": { "kernelspec": { "display_name": "base", "language": "python", "name": "python3" }, "language_info": { "codemirror_mode": { "name": "ipython", "version": 3 }, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.12" }, "orig_nbformat": 4, "vscode": { "interpreter": { "hash": "44accbcf0d44724f4687acb9e94a82a63737321ce87faf6d4ac50bb441ea44e2" } } }, "nbformat": 4, "nbformat_minor": 2 }]]></summary></entry><entry><title type="html">Cal State University San Marcos Engineering Presentation</title><link href="https://clairehzhao.github.io/claire/markdown/2023/03/28/csusm.html" rel="alternate" type="text/html" title="Cal State University San Marcos Engineering Presentation" /><published>2023-03-28T00:00:00-05:00</published><updated>2023-03-28T00:00:00-05:00</updated><id>https://clairehzhao.github.io/claire/markdown/2023/03/28/csusm</id><author><name></name></author><category term="markdown" /><summary type="html"><![CDATA[Notes on CSUSM]]></summary></entry><entry><title type="html">Data Structures- Space and Time Complexity</title><link href="https://clairehzhao.github.io/claire/2023/03/22/DS-space_time_complexity1.html" rel="alternate" type="text/html" title="Data Structures- Space and Time Complexity" /><published>2023-03-22T00:00:00-05:00</published><updated>2023-03-22T00:00:00-05:00</updated><id>https://clairehzhao.github.io/claire/2023/03/22/DS-space_time_complexity1</id><author><name></name></author><summary type="html"><![CDATA[Observing the time complexity of different algorithms]]></summary></entry></feed>